import asyncio
import sys
from typing import List

from loguru import logger

from src.scrapers import SimpleScraper
from src.strategies import DFSCrawlingStrategy, BFSCrawlingStrategy
from src.runner import AsyncRunner, AsyncManyRunner
from src.utils.installation import ensure_chromium_installed


async def demo_async_runner():
    """
    Demo sá»­ dá»¥ng AsyncRunner vá»›i má»™t URL.
    """
    print("\n" + "="*50)
    print("DEMO ASYNC RUNNER")
    print("="*50)
    
    try:
        # Táº¡o scraper
        scraper = SimpleScraper(auto_start=False)
        
        # Táº¡o DFS strategy
        dfs_strategy = DFSCrawlingStrategy(
            scraper=scraper,
            max_depth=2,
            max_pages=5
        )
        
        # Táº¡o AsyncRunner
        async with AsyncRunner(strategy=dfs_strategy, scraper=scraper) as runner:
            # Crawl má»™t URL
            SAMPLE_URL = "https://vnexpress.net/ong-chu-chatgpt-tiet-lo-cong-viec-se-lam-neu-bi-ai-thay-the-4947310.html"
            print(f"Äang crawl vá»›i AsyncRunner (DFS strategy): {SAMPLE_URL}")
            
            # Thá»±c thi crawling
            result = await runner.run(SAMPLE_URL)
            
            # In káº¿t quáº£
            print(f"âœ… HoÃ n thÃ nh crawling!")
            print(f"ğŸ“„ Tá»•ng sá»‘ trang: {result.total_pages}")
            print(f"ğŸ”— Tá»•ng sá»‘ liÃªn káº¿t: {len(result.get_all_links())}")
            print(f"ğŸ–¼ï¸ Tá»•ng sá»‘ hÃ¬nh áº£nh: {len(result.get_all_images())}")
            print(f"â±ï¸ Thá»i gian thá»±c hiá»‡n: {result.duration:.2f} giÃ¢y")
            print(f"ğŸ“ˆ Tá»· lá»‡ thÃ nh cÃ´ng: {result.success_rate:.2%}")
            
            # In thá»‘ng kÃª tá»« runner
            stats = runner.get_stats()
            print(f"ğŸ“Š Thá»‘ng kÃª runner: {stats}")
            
    except Exception as e:
        logger.error(f"Lá»—i trong demo AsyncRunner: {e}")


async def demo_async_many_runner():
    """
    Demo sá»­ dá»¥ng AsyncManyRunner vá»›i nhiá»u URLs.
    """
    print("\n" + "="*50)
    print("DEMO ASYNC MANY RUNNER")
    print("="*50)
    
    try:
        # URLs Ä‘á»ƒ crawl
        urls = [
            "https://vnexpress.net/",
            "https://tuoitre.vn/",
            "https://thanhnien.vn/"
        ]
        
        # Táº¡o strategy factory
        def bfs_strategy_factory():
            scraper = SimpleScraper(auto_start=False)
            return BFSCrawlingStrategy(
                scraper=scraper,
                max_depth=1,
                max_pages=3
            )
        
        # Táº¡o AsyncManyRunner
        async with AsyncManyRunner(
            strategy_factory=bfs_strategy_factory,
            max_concurrent=2
        ) as runner:
            print(f"Äang crawl {len(urls)} URLs vá»›i AsyncManyRunner (BFS strategy)...")
            
            # Progress callback
            def progress_callback(results):
                completed = len(results)
                total_pages = sum(len(r.scraped_pages) for r in results)
                print(f"ğŸ“ˆ Tiáº¿n trÃ¬nh: {completed}/{len(urls)} URLs hoÃ n thÃ nh, {total_pages} trang Ä‘Ã£ crawl")
            
            # Thá»±c thi crawling vá»›i progress callback
            results = await runner.run_with_progress(urls, progress_callback=progress_callback)
            
            # In káº¿t quáº£ tá»•ng há»£p
            print(f"\nâœ… HoÃ n thÃ nh crawling táº¥t cáº£ URLs!")
            total_pages = sum(len(r.scraped_pages) for r in results)
            total_links = sum(len(r.get_all_links()) for r in results)
            total_images = sum(len(r.get_all_images()) for r in results)
            total_duration = sum(r.duration or 0 for r in results)
            avg_success_rate = sum(r.success_rate for r in results) / len(results) if results else 0
            
            print(f"ğŸ“„ Tá»•ng sá»‘ trang: {total_pages}")
            print(f"ğŸ”— Tá»•ng sá»‘ liÃªn káº¿t: {total_links}")
            print(f"ğŸ–¼ï¸ Tá»•ng sá»‘ hÃ¬nh áº£nh: {total_images}")
            print(f"â±ï¸ Tá»•ng thá»i gian: {total_duration:.2f} giÃ¢y")
            print(f"ğŸ“ˆ Tá»· lá»‡ thÃ nh cÃ´ng trung bÃ¬nh: {avg_success_rate:.2%}")
            
            # In thá»‘ng kÃª tá»« runner
            stats = runner.get_stats()
            print(f"ğŸ“Š Thá»‘ng kÃª runner: {stats}")
            
    except Exception as e:
        logger.error(f"Lá»—i trong demo AsyncManyRunner: {e}")


async def main():
    """
    Main function that ensures Chromium is installed and then performs crawling operations.
    """
    print("Starting web crawler...")
    print("Chromium driver is ready.")
    
    # Demo AsyncRunner
    await demo_async_runner()
    
    # Demo AsyncManyRunner
    # await demo_async_many_runner()
    
    print("\n" + "="*50)
    print("HOÃ€N Táº¤T Táº¤T Cáº¢ DEMOS")
    print("="*50)


if __name__ == "__main__":
    # Ensure Chromium is installed
    if not ensure_chromium_installed():
        print("Failed to install Chromium. Exiting...")
        sys.exit(1)

    asyncio.run(main())
