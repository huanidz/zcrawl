"""
Test script Ä‘á»ƒ kiá»ƒm tra cÃ¡c thay Ä‘á»•i trong crawling strategies.
"""

import asyncio
from src.scrapers import SimpleScraper
from src.strategies import DFSCrawlingStrategy, BFSCrawlingStrategy


async def test_bfs_strategy():
    """
    Test BFS strategy vá»›i max_depth=2 Ä‘á»ƒ Ä‘áº£m báº£o nÃ³ crawl táº¥t cáº£ links trong pháº¡m vi max_depth.
    """
    print("\n" + "="*50)
    print("TEST BFS STRATEGY")
    print("="*50)
    
    try:
        # Táº¡o scraper
        scraper = SimpleScraper()
        await scraper.start()
        
        # Táº¡o BFS strategy vá»›i max_depth=2 vÃ  max_pages=10
        bfs_strategy = BFSCrawlingStrategy(
            scraper=scraper,
            max_depth=2,
            max_pages=10,
            respect_robots_txt=False
        )
        
        # Crawl má»™t URL cÃ³ nhiá»u links
        SAMPLE_URL = "https://example.com/"
        print(f"Äang crawl vá»›i BFS strategy: {SAMPLE_URL}")
        print(f"Max depth: {bfs_strategy.max_depth}, Max pages: {bfs_strategy.max_pages}")
        
        # Thá»±c thi crawling
        result = await bfs_strategy.crawl(SAMPLE_URL)
        
        # In káº¿t quáº£
        print(f"âœ… HoÃ n thÃ nh crawling BFS!")
        print(f"ğŸ“„ Tá»•ng sá»‘ trang Ä‘Ã£ crawl: {len(result.scraped_pages)}")
        print(f"ğŸ”— Tá»•ng sá»‘ liÃªn káº¿t tÃ¬m tháº¥y: {len(result.get_all_links())}")
        print(f"ğŸ–¼ï¸ Tá»•ng sá»‘ hÃ¬nh áº£nh: {len(result.get_all_images())}")
        print(f"â±ï¸ Thá»i gian thá»±c hiá»‡n: {result.duration:.2f} giÃ¢y" if result.duration else "â±ï¸ Thá»i gian thá»±c hiá»‡n: N/A")
        print(f"ğŸ“ˆ Tá»· lá»‡ thÃ nh cÃ´ng: {result.success_rate:.2%}")
        
        # In danh sÃ¡ch cÃ¡c URL Ä‘Ã£ crawl
        print("\nğŸ“‹ Danh sÃ¡ch cÃ¡c URL Ä‘Ã£ crawl:")
        for i, page in enumerate(result.scraped_pages):
            print(f"  {i+1}. {page.url}")
        
        return result
        
    except Exception as e:
        print(f"âŒ Lá»—i trong test BFS strategy: {e}")
        return None


async def test_dfs_strategy():
    """
    Test DFS strategy vá»›i max_depth=2 Ä‘á»ƒ Ä‘áº£m báº£o nÃ³ crawl táº¥t cáº£ links trong pháº¡m vi max_depth.
    """
    print("\n" + "="*50)
    print("TEST DFS STRATEGY")
    print("="*50)
    
    try:
        # Táº¡o scraper
        scraper = SimpleScraper()
        await scraper.start()
        
        # Táº¡o DFS strategy vá»›i max_depth=2 vÃ  max_pages=10
        dfs_strategy = DFSCrawlingStrategy(
            scraper=scraper,
            max_depth=2,
            max_pages=10,
            respect_robots_txt=False
        )
        
        # Crawl má»™t URL cÃ³ nhiá»u links
        SAMPLE_URL = "https://example.com/"
        print(f"Äang crawl vá»›i DFS strategy: {SAMPLE_URL}")
        print(f"Max depth: {dfs_strategy.max_depth}, Max pages: {dfs_strategy.max_pages}")
        
        # Thá»±c thi crawling
        result = await dfs_strategy.crawl(SAMPLE_URL)
        
        # In káº¿t quáº£
        print(f"âœ… HoÃ n thÃ nh crawling DFS!")
        print(f"ğŸ“„ Tá»•ng sá»‘ trang Ä‘Ã£ crawl: {len(result.scraped_pages)}")
        print(f"ğŸ”— Tá»•ng sá»‘ liÃªn káº¿t tÃ¬m tháº¥y: {len(result.get_all_links())}")
        print(f"ğŸ–¼ï¸ Tá»•ng sá»‘ hÃ¬nh áº£nh: {len(result.get_all_images())}")
        print(f"â±ï¸ Thá»i gian thá»±c hiá»‡n: {result.duration:.2f} giÃ¢y" if result.duration else "â±ï¸ Thá»i gian thá»±c hiá»‡n: N/A")
        print(f"ğŸ“ˆ Tá»· lá»‡ thÃ nh cÃ´ng: {result.success_rate:.2%}")
        
        # In danh sÃ¡ch cÃ¡c URL Ä‘Ã£ crawl
        print("\nğŸ“‹ Danh sÃ¡ch cÃ¡c URL Ä‘Ã£ crawl:")
        for i, page in enumerate(result.scraped_pages):
            print(f"  {i+1}. {page.url}")
        
        return result
        
    except Exception as e:
        print(f"âŒ Lá»—i trong test DFS strategy: {e}")
        return None


async def main():
    """
    Main function Ä‘á»ƒ test cáº£ hai strategies.
    """
    print("Báº¯t Ä‘áº§u test crawling strategies...")
    
    try:
        # Test BFS strategy
        bfs_result = await test_bfs_strategy()
        
        # Test DFS strategy
        dfs_result = await test_dfs_strategy()
        
        # So sÃ¡nh káº¿t quáº£
        if bfs_result and dfs_result:
            print("\n" + "="*50)
            print("SO SÃNH Káº¾T QUáº¢")
            print("="*50)
            print(f"BFS - Sá»‘ trang: {len(bfs_result.scraped_pages)}, Sá»‘ liÃªn káº¿t: {len(bfs_result.get_all_links())}")
            print(f"DFS - Sá»‘ trang: {len(dfs_result.scraped_pages)}, Sá»‘ liÃªn káº¿t: {len(dfs_result.get_all_links())}")
            
            # Kiá»ƒm tra xem cÃ³ duplicate URLs khÃ´ng
            bfs_urls = {page.url for page in bfs_result.scraped_pages}
            dfs_urls = {page.url for page in dfs_result.scraped_pages}
            
            print(f"BFS - Sá»‘ URLs duy nháº¥t: {len(bfs_urls)}")
            print(f"DFS - Sá»‘ URLs duy nháº¥t: {len(dfs_urls)}")
            
            if len(bfs_urls) == len(bfs_result.scraped_pages):
                print("âœ… BFS khÃ´ng cÃ³ duplicate URLs")
            else:
                print("âŒ BFS cÃ³ duplicate URLs")
                
            if len(dfs_urls) == len(dfs_result.scraped_pages):
                print("âœ… DFS khÃ´ng cÃ³ duplicate URLs")
            else:
                print("âŒ DFS cÃ³ duplicate URLs")
        
        print("\nâœ… HoÃ n thÃ nh test táº¥t cáº£ strategies!")
        
    except Exception as e:
        print(f"âŒ Lá»—i trong main: {e}")


if __name__ == "__main__":
    asyncio.run(main())